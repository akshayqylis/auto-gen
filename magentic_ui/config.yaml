# config.yaml

######################################
# Default OpenAI model configuration #
######################################
model_config: &client
  provider: autogen_ext.models.openai.OpenAIChatCompletionClient
  config:
    model: meta-llama/Llama-3.1-8B-Instruct
    api_key: empty
    model_info:
      vision: false
      function_calling: true
      json_output: true
      family: llama
      structured_output: true
    base_url: https://g3.ai.qylis.com/llama3/v1



##########################
# Clients for each agent #
##########################
orchestrator_client: *client
coder_client: *client
web_surfer_client: *client
file_surfer_client: *client
action_guard_client: *client